# Delta-Gamma GLMs

# Goals

- Learn how to model positive-continuous response data with zeros using
  delta-Gamma GLMs
- Introduce modelling spatial data with GAMs
- Practice a variety of approaches to plotting model predictions

# Data

We will start by reading in example trawl survey data for Pacific ocean perch
(POP) in Queen Charlotte Sound from the 2015 survey. These surveys are
conducted by DFO out of Pacific biological station. The coordinates have been
converted into UTMs so that the distance between coordinates is constant. There
are many ways of doing this. One way is with the `PBSmapping::convUL()`
function.

We will work with 2 data frames. The first, `pop` contains the collect the data
that we will model. The second, `qcs` contains a grid of coordinates and depths
across the entire survey area in Queen Charlotte Sound. We will use this second
data frame to make predictions about the density of fish across the entire
survey area.

```{r data}
library(tidyverse)
pop <- readRDS("data/raw/pop-qcs-2015.rds") %>%
  mutate(X = X/10, Y = Y/10)
qcs <- readRDS("data/raw/prediction-grid-qcs.rds") %>%
  rename(depth = akima_depth) %>%
  mutate(X = X/10, Y = Y/10) %>%
  filter(Y > 56.5, depth > min(pop$depth), depth < max(pop$depth))
pop <- mutate(pop, present = density > 0)
```

Let's plot the data. We will plot the locations where there were none of the
fish caught with x's. We will use circles with the area proportional to the
density of the fish caught for when they were caught.

```{r}
ggplot(pop) +
  geom_point(aes(X, Y, shape = present, size = density)) +
  scale_shape_manual(values = c("TRUE" = 21, "FALSE" = 4)) +
  scale_size_continuous(range = c(1, 8)) +
  coord_equal()
```

# Delta-Gamma GLM

Let's start by fitting a Gamma GLM with a log link to the tows where we do
observe fish.

```{r}
m_pos <- glm(density ~ poly(depth, 2), data = filter(pop, density > 0),
  family = Gamma(link = "log"))
arm::display(m_pos)
```

And we can fit a binomial GLM with a logit link to whether or not we observed
fish in a given tow.

```{r}
m_bin <- glm(present ~ poly(depth, 2), data = pop,
  family = binomial(link = "logit"))
arm::display(m_bin)
```

Let's make predictions from these models on the full grid data set so we can
plot them:

```{r}
qcs$positive_prediction <- predict(m_pos, newdata = qcs, type = "response")
qcs$binary_prediction <- predict(m_bin, newdata = qcs, type = "response")
```

We can combine these 2 predictions by multiplying the probability from the
binary model with the expected density from the positive model.

```{r}
qcs <- mutate(qcs, combined_prediction = binary_prediction * positive_prediction)
```

Let's make maps of those predictions

```{r}
ggplot(qcs, aes(X, Y, fill = positive_prediction)) +
  geom_raster() +
  viridis::scale_fill_viridis(trans = "sqrt") +
  coord_equal()

ggplot(qcs, aes(X, Y, fill = binary_prediction)) +
  geom_raster() +
  scale_fill_gradient2(midpoint = 0.5, 
    low = scales::muted("blue"), high = scales::muted("red")) +
  coord_equal()

ggplot(qcs, aes(X, Y, fill = combined_prediction)) +
  geom_raster() +
  viridis::scale_fill_viridis(trans = "sqrt", option = "C") +
  coord_equal()
```

We know these data are spatially collected. Let's check the residuals from the
positive model in space.

```{r}
pop$positive_prediction_log <- predict(m_pos, type = "link", newdata = pop)
pop$residual_pos <- pop$positive_prediction_log - log(pop$density)

ggplot(pop, aes(X, Y, colour = residual_pos, shape = present, size = density)) +
  geom_point() +
  scale_shape_manual(values = c("TRUE" = 20, "FALSE" = 4)) +
  scale_size_continuous(range = c(3, 8)) +
  coord_equal() +
  scale_fill_gradient2(midpoint = 0.5, 
    low = scales::muted("blue"), high = scales::muted("red"))
```

Do you see any problems?

# Delta-Gamma GAM

One method of dealing with the spatial autocorrelation (residuals closer to
each other are more similar than residuals further apart from each other) is to
include a 2-dimensional smoother with a GAM. Why might we want to use a GAM
here? What are some other options?

Let's fit the same models as before but this time we will substitute
`mgcv::gam` for `glm` and we will add a 2-dimension smoother with `mgcv::te`.
The `te`, as opposed to `s`, which you might have seen before, allows for the
wiggliness to be different in the 2 dimensions. You typically would want to
allow for this in a spatial model if you think moving south to north is
different than moving east to west. That certainly is the case in the ocean
when we are close to the coast.

```{r}
library(mgcv)
m_pos <- gam(density ~ poly(depth, 2) + te(X, Y), data = filter(pop, density > 0),
  family = Gamma(link = "log"))
summary(m_pos)
m_bin <- gam(present ~ poly(depth, 2) + te(X, Y), data = pop,
  family = binomial(link = "logit"))
summary(m_bin)
```

There are variety of ways we can look at the 2-dimensional smoother. Here are 2:

```{r}
plot(m_pos, scheme = 2)
plot(m_pos, pers = TRUE)
plot(m_bin, scheme = 2)
plot(m_bin, pers = TRUE)
```

We can make our individual model predictions and our combined predictions the
same way as before:

```{r}
qcs$positive_prediction <- predict(m_pos, newdata = qcs, type = "response")
qcs$binary_prediction <- predict(m_bin, newdata = qcs, type = "response")
qcs <- mutate(qcs, combined_prediction = binary_prediction * positive_prediction)
```

And plot those predictions:

```{r}
ggplot(qcs, aes(X, Y, fill = positive_prediction)) +
  geom_raster() +
  viridis::scale_fill_viridis(trans = "sqrt") +
  coord_equal()

ggplot(qcs, aes(X, Y, fill = binary_prediction)) +
  geom_raster() +
  scale_fill_gradient2(midpoint = 0.5, 
    low = scales::muted("blue"), high = scales::muted("red")) +
  coord_equal()
```

Let's plot the combined predictions along with the data overlaid:

```{r}
ggplot(qcs, aes(X, Y, fill = combined_prediction)) +
  geom_raster() +
  viridis::scale_fill_viridis(option = "C", trans = "sqrt") +
  geom_point(data = pop, aes(X, Y, shape = present, size = density), inherit.aes = FALSE) +
  scale_shape_manual(values = c("TRUE" = 21, "FALSE" = 4)) +
  scale_size_continuous(range = c(1, 8)) +
  coord_equal()
```

And look at the spatial residuals again:

```{r}
pop$residual_pos <- NA # create an empty column
pop$positive_prediction_log <- predict(m_pos, type = "link", newdata = pop)
pop$residual_pos <- pop$positive_prediction_log - log(pop$density)

ggplot(pop, aes(X, Y, colour = residual_pos, shape = present, size = density)) +
  geom_point() +
  scale_shape_manual(values = c("TRUE" = 20, "FALSE" = 4)) +
  scale_size_continuous(range = c(3, 8)) +
  coord_equal() +
  scale_color_gradient2(midpoint = 0.5)
```

That looks considerably better than before, although perhaps not perfect. Note
that we are only looking at the positive component of the model here, partly
because that is the easiest one to inspect in this case.

## Plotting the effects of predictors

One useful plot we could make would be the marginal effect of an individual
predictor. In this case, we would probably be interested in plotting the effect
of various depths on the probability of observing a fish, on the density of
fish given that we observe some, and on the overall expected density of fish.

To do that, we will create a new data frame with a sequence of depths to predict
on. Because our model also includes latitude and longitude coordinates, and we
are going to make predictions, we will also have to set these predictors at
a given level. Because they do not interact with the depth predictors, they will
not change the slope within a given model but they will shift the predictions
up or down. In this case it will also have a slight effect on the overall shape
because we are combining the 2 models on the 'natural' or 'raw' response scale
not the link scale.

```{r}
nd <- tibble::tibble(depth = seq(min(pop$depth), max(pop$depth), length.out = 100),
  X = mean(pop$X), Y = mean(pop$Y))
```

Let's extract the estimates and standard errors from both predictions on our new
data frame.

```{r}
p_pos <- predict(m_pos, newdata = nd, type = "link", se.fit = TRUE)
nd$pos <- p_pos$fit
nd$pos_se <- p_pos$se.fit

p_bin <- predict(m_bin, newdata = nd, type = "link", se.fit = TRUE)
nd$bin <- p_bin$fit
nd$bin_se <- p_bin$se.fit
```

Let's plot the productions along with 95% CIs:

```{r}
ggplot(nd, aes(depth, exp(pos))) + geom_line() +
  geom_ribbon(aes(
    ymin = exp(pos - 1.96 * pos_se),
    ymax = exp(pos + 1.96 * pos_se)), alpha = 0.3)

ggplot(nd, aes(depth, plogis(bin))) + geom_line() +
  geom_ribbon(aes(
    ymin = plogis(bin - 1.96 * bin_se),
    ymax = plogis(bin + 1.96 * bin_se)), alpha = 0.3)
```

Again, we can combine the predictions into our overall expected fish density for
a given depth and at our mean latitude and longitude:

```{r}
ggplot(nd, aes(depth, plogis(bin) * exp(pos))) +
  geom_line() +
  geom_line(aes(y = exp(pos)), lty = 2)
```

Can we easily combine the standard errors to come up with the confidence
interval in the last plot? Why or why not? How could we go about calculating
the confidence intervals on those predictions?

- Bootstrap, e.g. <http://seananderson.ca/2014/05/18/gamma-hurdle.html>
- MCMC (Markov chain Monte Carlo) (perhaps via the rstanarm package; simply
  multiply the MCMC samples from the 2 models together and summarize them)
- The Delta method, perhaps implemented through something like TMB (contact me
  if you're interested, I have working examples of this)

# More information

- http://seananderson.ca/2014/05/18/gamma-hurdle.html
- Shelton, A.O., Thorson, J.T., Ward, E.J., and Feist, B.E. (2014). Spatial
  semiparametric models improve estimates of species abundance and distribution.
  Can. J. Fish. Aquat. Sci.
  <https://doi.org/10.1139/cjfas-2013-0508>


## glmmfields

Although it's beyond the scope of the current lesson, we could also fit our
models with a model that treats the spatial pattern as random effects through
something called a "random field". I've been developing an R package to make it
easy to fit these kinds of models. Below is an example of the Gamma GLM fit with
glmmfields. <https://github.com/seananderson/glmmfields#readme>

```{r, include=FALSE}
has_glmmfields <- require("glmmfields") 
```

```{r glmmfields, eval=has_glmmfields, cache=TRUE}
# install.packages("devtools")
# devtools::install_github("seananderson/glmmfields")
library("glmmfields")

options(mc.cores = parallel::detectCores())
m_pos <- glmmfields(density ~ arm::rescale(depth) + I(arm::rescale(depth)^2),
  data = filter(pop, density > 0),
  family = Gamma(link = "log"),
  lat = "Y", lon = "X", chains = 2,
  iter = 500,
  nknots = 20, seed = 1)
m_pos

pred <- predict(m_pos, newdata = data.frame(qcs, time = 1), type = "response")
qcs_plot <- data.frame(qcs, pred)

lims <- range(c(qcs_plot$estimate, qcs_plot$conf_low, qcs_plot$conf_high))

# Credible intervals:
g <- ggplot(qcs_plot, aes(X, Y, fill = estimate)) +
  geom_raster() + coord_equal() +
  viridis::scale_fill_viridis(trans = "sqrt", limits = lims, option = "C")

g1 <- ggplot(qcs_plot, aes(X, Y, fill = conf_low)) +
  geom_raster() + coord_equal() +
  viridis::scale_fill_viridis(trans = "sqrt", limits = lims, option = "C")

g2 <- ggplot(qcs_plot, aes(X, Y, fill = conf_high)) +
  geom_raster() + coord_equal() +
  viridis::scale_fill_viridis(trans = "sqrt", limits = lims, option = "C")

gridExtra::grid.arrange(g1, g, g2, nrow = 2)
```
